{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import RobustScaler\n",
    "from pyspark.sql.types import IntegerType, DoubleType\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.functions import *\n",
    "from time import time\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import rand\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FraudDetection():\n",
    "    def __init__(self):\n",
    "        self.spark = None\n",
    "        self.data = None\n",
    "        self.rep_data = None # repeated data\n",
    "        \n",
    "    def create_spark_context(self, ram, rpt=False, ret=False):\n",
    "        self.spark = SparkSession.\\\n",
    "            builder.\\\n",
    "            appName(\"Fraud Detector\").\\\n",
    "            master(\"spark://spark-master:7077\").\\\n",
    "            config(\"spark.executor.memory\", \"{}g\".format(ram)).\\\n",
    "            getOrCreate()\n",
    "        if rpt: print(self.spark.sparkContext.getConf().getAll())\n",
    "        if ret: return self.spark\n",
    "    \n",
    "    def read_file(self, path, rpt=False, ret=False):\n",
    "        self.data = self.spark.read.csv(path, header=True, inferSchema=True)\n",
    "        if rpt: print('number of partitions: {}'.format(self.data.rdd.getNumPartitions()))\n",
    "        if ret: return self.data\n",
    "    \n",
    "    def data_duplicator(self, number, rpt=False, ret=False):\n",
    "        self.rep_data = self.data\n",
    "        for i in range(number-1):\n",
    "            self.rep_data = self.data.union(self.rep_data)\n",
    "        if rpt: print(\"Created df with: {}, {}\".format(self.rep_data .count(), len(self.rep_data .columns)))\n",
    "        if ret: return self.rep_data\n",
    "\n",
    "        \n",
    "class Preprocess():\n",
    "    def __init__(self, data):\n",
    "        self.spark = None\n",
    "        self.sub_sample = None\n",
    "        self.data = data\n",
    "        \n",
    "    def scale_column(self, feature):\n",
    "        self.data = self.data.withColumn(feature, self.data[feature].cast(IntegerType()))\n",
    "        assembler = VectorAssembler().setInputCols([feature]).setOutputCol('f'+feature)\n",
    "        self.data = assembler.transform(self.data)\n",
    "        self.data = self.data.drop(feature)\n",
    "        scaler = RobustScaler(inputCol=\"f\"+feature, outputCol=feature,\n",
    "                          withScaling=True, withCentering=False,\n",
    "                          lower=0.25, upper=0.75)\n",
    "        scalerModel = scaler.fit(self.data)\n",
    "        self.data = scalerModel.transform(self.data)\n",
    "        self.data = self.data.drop('f'+feature)\n",
    "        unlist = udf(lambda x: float(list(x)[0]), DoubleType())\n",
    "        self.data = self.data.withColumn(feature, unlist(feature))\n",
    "        return self.data\n",
    "    \n",
    "    def robust_scale(self, scale_columns):\n",
    "        for column in scale_columns:\n",
    "            self.data = self.scale_column(column)\n",
    "        return self.data\n",
    "    \n",
    "    def calculate_iqr_bound(self, feature, q1, q3, k, rpt=False):\n",
    "        bound = self.sub_sample.filter(self.data.Class==1).approxQuantile(feature, [q1, q3], 0)\n",
    "        if rpt: print(f'Feature: {feature}, Lower bound: {bound[0]}, Upper bound: {bound[1]}')\n",
    "        iqr = bound[1] - bound[0]\n",
    "        if rpt: print(f'Feature: {feature}, IQR: {iqr}')\n",
    "        bound[0] = bound[0] - (iqr * k)\n",
    "        bound[1] = bound[1] + (iqr * k)\n",
    "        if rpt: print(f'Feature: {feature}, Cut-off Lower bound: {bound[0]}, Cut-off Upper bound: {bound[1]}')\n",
    "        return bound\n",
    "    \n",
    "    def outlier_removal(self, features, q1=0.25, q3=0.75, k=1.5, rpt=False):\n",
    "        frauds = self.data.filter(self.data.Class==1)\n",
    "        self.sub_sample = frauds.union(self.data.filter(self.data.Class==0).limit(492))\n",
    "        for feature in features:\n",
    "            before_removal_count = self.sub_sample.count()\n",
    "            bound = self.calculate_iqr_bound(feature, q1, q3, k, rpt=rpt)\n",
    "            self.sub_sample = self.sub_sample.filter((col(feature) >= bound[0]) & (col(feature) <= bound[1]))\n",
    "            after_removal_count = self.sub_sample.count()\n",
    "            if rpt: print(f'before removal count: {before_removal_count}, after removal count: {after_removal_count}')\n",
    "    \n",
    "    def assemble_features(self):\n",
    "        assembler = VectorAssembler(inputCols=['V{}'.format(i) for i in range(1,29)], outputCol='features')\n",
    "        self.data = assembler.transform(self.data)\n",
    "        return self.data\n",
    "\n",
    "    \n",
    "class Evaluator():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def accuracy(self, data):\n",
    "        accuracy_evaluator = MulticlassClassificationEvaluator(labelCol=\"prediction\", predictionCol=\"class\", metricName=\"accuracy\")\n",
    "        print('accuracy: {}'.format(accuracy_evaluator.evaluate(data)))\n",
    "        \n",
    "    def recall(self, data):\n",
    "        recall_evaluator = MulticlassClassificationEvaluator(labelCol=\"prediction\", predictionCol=\"class\", metricName=\"recallByLabel\")\n",
    "        print('recall: {}'.format(recall_evaluator.evaluate(data)))\n",
    "    \n",
    "    def recall(self, data):\n",
    "        recall_evaluator = MulticlassClassificationEvaluator(labelCol=\"prediction\", predictionCol=\"class\", metricName=\"recallByLabel\")\n",
    "        print('recall: {}'.format(recall_evaluator.evaluate(data))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of partitions: 8\n",
      "Created df with: 1783929, 10\n"
     ]
    }
   ],
   "source": [
    "ram=16\n",
    "duplicate=3\n",
    "splitation=[0.7, 0.1, 0.2]\n",
    "detector = FraudDetection()\n",
    "detector.create_spark_context(ram=ram)\n",
    "detector.read_file(\"/opt/workspace/bank_sim.csv\", True)\n",
    "detector.data_duplicator(duplicate, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------+---+------+----------+-------------+-----------+-------------------+------+-----+\n",
      "|step|     customer|age|gender|zipcodeOri|     merchant|zipMerchant|           category|amount|fraud|\n",
      "+----+-------------+---+------+----------+-------------+-----------+-------------------+------+-----+\n",
      "|   0|'C1093826151'|'4'|   'M'|   '28007'| 'M348934600'|    '28007'|'es_transportation'|  4.55|    0|\n",
      "|   0| 'C352968107'|'2'|   'M'|   '28007'| 'M348934600'|    '28007'|'es_transportation'| 39.68|    0|\n",
      "|   0|'C2054744914'|'4'|   'F'|   '28007'|'M1823072687'|    '28007'|'es_transportation'| 26.89|    0|\n",
      "|   0|'C1760612790'|'3'|   'M'|   '28007'| 'M348934600'|    '28007'|'es_transportation'| 17.25|    0|\n",
      "|   0| 'C757503768'|'5'|   'M'|   '28007'| 'M348934600'|    '28007'|'es_transportation'| 35.72|    0|\n",
      "+----+-------------+---+------+----------+-------------+-----------+-------------------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "detector.data.limit(5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = detector.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(customer=\"'C1316262830'\", sum(amount)=6024.37),\n",
       " Row(customer=\"'C1089903335'\", sum(amount)=5546.180000000001),\n",
       " Row(customer=\"'C483009385'\", sum(amount)=5346.830000000001),\n",
       " Row(customer=\"'C1983734850'\", sum(amount)=6931.089999999999),\n",
       " Row(customer=\"'C1815981756'\", sum(amount)=4952.500000000001),\n",
       " Row(customer=\"'C1028143403'\", sum(amount)=5960.92),\n",
       " Row(customer=\"'C328208842'\", sum(amount)=6255.51),\n",
       " Row(customer=\"'C1475317372'\", sum(amount)=8966.54),\n",
       " Row(customer=\"'C1873446390'\", sum(amount)=3674.49),\n",
       " Row(customer=\"'C135716487'\", sum(amount)=4507.99)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupBy(df.customer).sum('amount').collect()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(customer=\"'C1316262830'\", avg(amount)=34.424971428571425),\n",
       " Row(customer=\"'C1089903335'\", avg(amount)=31.51238636363637),\n",
       " Row(customer=\"'C483009385'\", avg(amount)=29.704611111111117),\n",
       " Row(customer=\"'C1983734850'\", avg(amount)=69.31089999999999),\n",
       " Row(customer=\"'C1815981756'\", avg(amount)=30.19817073170732),\n",
       " Row(customer=\"'C1028143403'\", avg(amount)=32.752307692307696),\n",
       " Row(customer=\"'C328208842'\", avg(amount)=35.143314606741576),\n",
       " Row(customer=\"'C1475317372'\", avg(amount)=81.51400000000001),\n",
       " Row(customer=\"'C1873446390'\", avg(amount)=40.827666666666666),\n",
       " Row(customer=\"'C135716487'\", avg(amount)=27.827098765432098)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupBy(df.customer).mean('amount').collect()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(zipcodeOri=\"'28007'\", count=594643)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupBy(df.zipcodeOri).count().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(merchant=\"'M857378720'\", count=122),\n",
       " Row(merchant=\"'M97925176'\", count=599),\n",
       " Row(merchant=\"'M1294758098'\", count=191),\n",
       " Row(merchant=\"'M1788569036'\", count=181),\n",
       " Row(merchant=\"'M348934600'\", count=205426),\n",
       " Row(merchant=\"'M1823072687'\", count=299693),\n",
       " Row(merchant=\"'M1416436880'\", count=220),\n",
       " Row(merchant=\"'M1535107174'\", count=1868),\n",
       " Row(merchant=\"'M50039827'\", count=916),\n",
       " Row(merchant=\"'M117188757'\", count=21),\n",
       " Row(merchant=\"'M1600850729'\", count=2624),\n",
       " Row(merchant=\"'M1748431652'\", count=274),\n",
       " Row(merchant=\"'M1726401631'\", count=3),\n",
       " Row(merchant=\"'M1888755466'\", count=912),\n",
       " Row(merchant=\"'M349281107'\", count=2881),\n",
       " Row(merchant=\"'M933210764'\", count=69),\n",
       " Row(merchant=\"'M480139044'\", count=3508),\n",
       " Row(merchant=\"'M980657600'\", count=1769),\n",
       " Row(merchant=\"'M495352832'\", count=69),\n",
       " Row(merchant=\"'M209847108'\", count=3814),\n",
       " Row(merchant=\"'M2080407379'\", count=48),\n",
       " Row(merchant=\"'M1873032707'\", count=250),\n",
       " Row(merchant=\"'M348875670'\", count=107),\n",
       " Row(merchant=\"'M855959430'\", count=6098),\n",
       " Row(merchant=\"'M78078399'\", count=1608),\n",
       " Row(merchant=\"'M1198415165'\", count=1580),\n",
       " Row(merchant=\"'M1353266412'\", count=78),\n",
       " Row(merchant=\"'M1649169323'\", count=1173),\n",
       " Row(merchant=\"'M1313686961'\", count=527),\n",
       " Row(merchant=\"'M1913465890'\", count=3988),\n",
       " Row(merchant=\"'M1946091778'\", count=5343),\n",
       " Row(merchant=\"'M692898500'\", count=900),\n",
       " Row(merchant=\"'M547558035'\", count=949),\n",
       " Row(merchant=\"'M677738360'\", count=358),\n",
       " Row(merchant=\"'M1400236507'\", count=776),\n",
       " Row(merchant=\"'M151143676'\", count=6373),\n",
       " Row(merchant=\"'M923029380'\", count=323),\n",
       " Row(merchant=\"'M1352454843'\", count=370),\n",
       " Row(merchant=\"'M732195782'\", count=608),\n",
       " Row(merchant=\"'M45060432'\", count=573),\n",
       " Row(merchant=\"'M1053599405'\", count=6821),\n",
       " Row(merchant=\"'M17379832'\", count=282),\n",
       " Row(merchant=\"'M840466850'\", count=1399),\n",
       " Row(merchant=\"'M2011752106'\", count=244),\n",
       " Row(merchant=\"'M2122776122'\", count=341),\n",
       " Row(merchant=\"'M1872033263'\", count=525),\n",
       " Row(merchant=\"'M1842530320'\", count=751),\n",
       " Row(merchant=\"'M85975013'\", count=26254),\n",
       " Row(merchant=\"'M3697346'\", count=308),\n",
       " Row(merchant=\"'M1741626453'\", count=528)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupBy(df.merchant).count().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
