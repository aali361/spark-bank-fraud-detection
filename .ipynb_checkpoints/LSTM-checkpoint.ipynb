{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers.recurrent import LSTM\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "\n",
    "from keras.layers import Dropout\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('creditcard.csv', na_filter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_original = np.array(X['Class'], dtype='float')\n",
    "X.drop(['Class'], inplace=True, axis=1)\n",
    "rolling_window_size = 10  ### this selects how many historical transactions should be analyzed to judge the transaction at hand -- RNN width\n",
    "X_interim = np.zeros([(X.shape[0]-rolling_window_size)*10,30])\n",
    "y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range((X.shape[0]-rolling_window_size)):\n",
    "    beg = 0+i\n",
    "    end = beg+rolling_window_size\n",
    "    s = np.array(X[beg:end], dtype='float')\n",
    "    X_interim[(rolling_window_size*i):(rolling_window_size*(i+1)),:] = s\n",
    "    y.append(y_original[end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(y, dtype='float')\n",
    "X_interim = X_interim[:,1::]\n",
    "X_tensor = X_interim.reshape(int(np.shape(X_interim)[0]/rolling_window_size), rolling_window_size, np.shape(X_interim)[1])\n",
    "test_train_split = 0.5\n",
    "stratify = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if stratify:\n",
    "    y = np.vstack((range(len(y)),y)).T\n",
    "    y_pos = y[y[:,1]==1]\n",
    "    y_neg = y[y[:,1]==0]\n",
    "    \n",
    "    y_pos = y_pos[np.random.choice(y_pos.shape[0], int(y_pos.shape[0]*test_train_split), replace=False),:]\n",
    "    y_neg = y_neg[np.random.choice(y_neg.shape[0], int(y_neg.shape[0]*test_train_split), replace=False),:]\n",
    "    \n",
    "    train_idx = np.array(np.hstack((y_pos[:,0],y_neg[:,0])), dtype='int')\n",
    "    \n",
    "    X_train = X_tensor[train_idx, :, :]\n",
    "    X_test = np.delete(X_tensor, train_idx, axis=0)\n",
    "    y_train = y[train_idx,1]\n",
    "    y_test = np.delete(y, train_idx, axis=0)\n",
    "    y_test = y_test[:,1]\n",
    "else: \n",
    "    train_idx = np.random.choice(X_tensor.shape[0], int(X_tensor.shape[0]*test_train_split), replace=False)\n",
    "    X_train = X_tensor[train_idx, :, :]\n",
    "    X_test = np.delete(X_tensor, train_idx, axis=0)\n",
    "    y_train = y[train_idx]\n",
    "    y_test = np.delete(y, train_idx, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del (X_tensor, y, stratify, test_train_split, train_idx, y_neg, y_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hyperparameters Tuning\n",
    "# First test optimal epochs holding everything else constant\n",
    "# Dropout: 0.1-0.6\n",
    "# GradientClipping: 0.1-10\n",
    "# BatchSize: 32,64,128,256,512 (power of 2)\n",
    "\n",
    "\n",
    "### Train LSTM using Keras 2 API ###\n",
    "model = Sequential()\n",
    "model.add(LSTM(20, input_shape=X_train.shape[1:], kernel_initializer='lecun_uniform', activation='relu', kernel_regularizer=regularizers.l1(0.1), recurrent_regularizer=regularizers.l1(0.01), bias_regularizer=None, activity_regularizer=None, dropout=0.2, recurrent_dropout=0.2))#, return_sequences=True))\n",
    "model.add(Dense(1, kernel_initializer='lecun_uniform', activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) #optimizer='rmsprop'\n",
    "# print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, epochs=200, batch_size=10000, class_weight={0 : 1., 1: float(int(1/np.mean(y_train)))}, validation_split=0.3)\n",
    "\n",
    "train_predict = model.predict(X_train)\n",
    "test_predict = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics \n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_train, train_predict, pos_label=1)\n",
    "print('TRAIN | AUC Score: ' + str((metrics.auc(fpr, tpr))))\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, test_predict, pos_label=1)\n",
    "print('TEST | AUC Score: ' + str((metrics.auc(fpr, tpr))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
