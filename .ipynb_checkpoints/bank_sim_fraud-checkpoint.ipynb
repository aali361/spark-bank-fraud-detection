{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import RobustScaler\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.sql.types import IntegerType, DoubleType\n",
    "from pyspark.sql.functions import udf, col, round\n",
    "from pyspark.sql.functions import *\n",
    "from time import time\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import rand\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FraudDetection():\n",
    "    def __init__(self):\n",
    "        self.spark = None\n",
    "        self.data = None\n",
    "        self.rep_data = None # repeated data\n",
    "        \n",
    "    def create_spark_context(self, ram, rpt=False, ret=False):\n",
    "        self.spark = SparkSession.\\\n",
    "            builder.\\\n",
    "            appName(\"Fraud Detector\").\\\n",
    "            master(\"spark://spark-master:7077\").\\\n",
    "            config(\"spark.executor.memory\", \"{}g\".format(ram)).\\\n",
    "            getOrCreate()\n",
    "        if rpt: print(self.spark.sparkContext.getConf().getAll())\n",
    "        if ret: return self.spark\n",
    "    \n",
    "    def read_file(self, path, rpt=False, ret=False):\n",
    "        self.data = self.spark.read.csv(path, header=True, inferSchema=True)\n",
    "        if rpt: print('number of partitions: {}'.format(self.data.rdd.getNumPartitions()))\n",
    "        if ret: return self.data\n",
    "    \n",
    "    def data_duplicator(self, number, rpt=False, ret=False):\n",
    "        self.rep_data = self.data\n",
    "        for i in range(number-1):\n",
    "            self.rep_data = self.data.union(self.rep_data)\n",
    "        if rpt: print(\"Created df with: {}, {}\".format(self.rep_data .count(), len(self.rep_data .columns)))\n",
    "        if ret: return self.rep_data\n",
    "\n",
    "        \n",
    "class Preprocess():\n",
    "    def __init__(self, data):\n",
    "        self.spark = None\n",
    "        self.sub_sample = None\n",
    "        self.data = data\n",
    "        \n",
    "    def scale_column(self, feature):\n",
    "        self.data = self.data.withColumn(feature, self.data[feature].cast(IntegerType()))\n",
    "        assembler = VectorAssembler().setInputCols([feature]).setOutputCol('f'+feature)\n",
    "        self.data = assembler.transform(self.data)\n",
    "        self.data = self.data.drop(feature)\n",
    "        scaler = RobustScaler(inputCol=\"f\"+feature, outputCol=feature,\n",
    "                          withScaling=True, withCentering=False,\n",
    "                          lower=0.25, upper=0.75)\n",
    "        scalerModel = scaler.fit(self.data)\n",
    "        self.data = scalerModel.transform(self.data)\n",
    "        self.data = self.data.drop('f'+feature)\n",
    "        unlist = udf(lambda x: float(list(x)[0]), DoubleType())\n",
    "        self.data = self.data.withColumn(feature, unlist(feature))\n",
    "        return self.data\n",
    "    \n",
    "    def robust_scale(self, scale_columns):\n",
    "        for column in scale_columns:\n",
    "            self.data = self.scale_column(column)\n",
    "        return self.data\n",
    "    \n",
    "    def calculate_iqr_bound(self, feature, q1, q3, k, rpt=False):\n",
    "        bound = self.sub_sample.filter(self.data.Class==1).approxQuantile(feature, [q1, q3], 0)\n",
    "        if rpt: print(f'Feature: {feature}, Lower bound: {bound[0]}, Upper bound: {bound[1]}')\n",
    "        iqr = bound[1] - bound[0]\n",
    "        if rpt: print(f'Feature: {feature}, IQR: {iqr}')\n",
    "        bound[0] = bound[0] - (iqr * k)\n",
    "        bound[1] = bound[1] + (iqr * k)\n",
    "        if rpt: print(f'Feature: {feature}, Cut-off Lower bound: {bound[0]}, Cut-off Upper bound: {bound[1]}')\n",
    "        return bound\n",
    "    \n",
    "    def outlier_removal(self, features, q1=0.25, q3=0.75, k=1.5, rpt=False):\n",
    "        frauds = self.data.filter(self.data.Class==1)\n",
    "        self.sub_sample = frauds.union(self.data.filter(self.data.Class==0).limit(492))\n",
    "        for feature in features:\n",
    "            before_removal_count = self.sub_sample.count()\n",
    "            bound = self.calculate_iqr_bound(feature, q1, q3, k, rpt=rpt)\n",
    "            self.sub_sample = self.sub_sample.filter((col(feature) >= bound[0]) & (col(feature) <= bound[1]))\n",
    "            after_removal_count = self.sub_sample.count()\n",
    "            if rpt: print(f'before removal count: {before_removal_count}, after removal count: {after_removal_count}')\n",
    "    \n",
    "    def assemble_features(self):\n",
    "        assembler = VectorAssembler(inputCols=['V{}'.format(i) for i in range(1,29)], outputCol='features')\n",
    "        self.data = assembler.transform(self.data)\n",
    "        return self.data\n",
    "\n",
    "    \n",
    "class Evaluator():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def accuracy(self, data):\n",
    "        accuracy_evaluator = MulticlassClassificationEvaluator(labelCol=\"prediction\", predictionCol=\"class\", metricName=\"accuracy\")\n",
    "        print('accuracy: {}'.format(accuracy_evaluator.evaluate(data)))\n",
    "        \n",
    "    def recall(self, data):\n",
    "        recall_evaluator = MulticlassClassificationEvaluator(labelCol=\"prediction\", predictionCol=\"class\", metricName=\"recallByLabel\")\n",
    "        print('recall: {}'.format(recall_evaluator.evaluate(data)))\n",
    "    \n",
    "    def recall(self, data):\n",
    "        recall_evaluator = MulticlassClassificationEvaluator(labelCol=\"prediction\", predictionCol=\"class\", metricName=\"recallByLabel\")\n",
    "        print('recall: {}'.format(recall_evaluator.evaluate(data))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of partitions: 8\n",
      "Created df with: 594643, 10\n"
     ]
    }
   ],
   "source": [
    "ram=16\n",
    "duplicate=1\n",
    "splitation=[0.7, 0.1, 0.2]\n",
    "detector = FraudDetection()\n",
    "detector.create_spark_context(ram=ram)\n",
    "detector.read_file(\"/opt/workspace/bank_sim.csv\", True)\n",
    "detector.data_duplicator(duplicate, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = detector.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------+---+------+----------+-------------+-----------+-------------------+------+-----+\n",
      "|step|     customer|age|gender|zipcodeOri|     merchant|zipMerchant|           category|amount|fraud|\n",
      "+----+-------------+---+------+----------+-------------+-----------+-------------------+------+-----+\n",
      "|   0|'C1093826151'|'4'|   'M'|   '28007'| 'M348934600'|    '28007'|'es_transportation'|  4.55|    0|\n",
      "|   0| 'C352968107'|'2'|   'M'|   '28007'| 'M348934600'|    '28007'|'es_transportation'| 39.68|    0|\n",
      "|   0|'C2054744914'|'4'|   'F'|   '28007'|'M1823072687'|    '28007'|'es_transportation'| 26.89|    0|\n",
      "|   0|'C1760612790'|'3'|   'M'|   '28007'| 'M348934600'|    '28007'|'es_transportation'| 17.25|    0|\n",
      "|   0| 'C757503768'|'5'|   'M'|   '28007'| 'M348934600'|    '28007'|'es_transportation'| 35.72|    0|\n",
      "+----+-------------+---+------+----------+-------------+-----------+-------------------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.limit(5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_column(df, column):\n",
    "    indexer = StringIndexer(inputCol=column, outputCol=column+\"Index\")\n",
    "    df = indexer.fit(df).transform(df)\n",
    "    df = df.withColumn(column, df[column+\"Index\"].cast(IntegerType()))\n",
    "    df = df.drop(column+\"Index\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = index_column(df, 'merchant')\n",
    "df = index_column(df, 'category')\n",
    "df = index_column(df, 'customer')\n",
    "df = index_column(df, 'age')\n",
    "df = index_column(df, 'gender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merchant_fraud_probablity(merchant):\n",
    "    merchant_df = df.filter(df.merchant==merchant)\n",
    "    return merchant_df.filter(merchant_df.fraud==1).count()/merchant_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "merchants = df.toPandas()['merchant'].unique()\n",
    "merchants_fraud_probablity = {}\n",
    "for merchant in merchants:\n",
    "    merchants_fraud_probablity[merchant] = merchant_fraud_probablity(int(merchant))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merchant_probablity(merchant):\n",
    "    return merchants_fraud_probablity[merchant]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rdd.map(lambda x: x + (merchant_probablity(x[\"merchant\"]),)).toDF(df.columns + [\"merchanttProbablity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+---+------+----------+--------+-----------+--------+------+-----+-------------------+\n",
      "|step|customer|age|gender|zipcodeOri|merchant|zipMerchant|category|amount|fraud|merchanttProbablity|\n",
      "+----+--------+---+------+----------+--------+-----------+--------+------+-----+-------------------+\n",
      "|   0|    1795|  2|     1|   '28007'|       1|    '28007'|       0|  4.55|    0|                0.0|\n",
      "|   0|    1620|  0|     1|   '28007'|       1|    '28007'|       0| 39.68|    0|                0.0|\n",
      "|   0|    3796|  2|     0|   '28007'|       0|    '28007'|       0| 26.89|    0|                0.0|\n",
      "|   0|    1273|  1|     1|   '28007'|       1|    '28007'|       0| 17.25|    0|                0.0|\n",
      "|   0|    2814|  3|     1|   '28007'|       1|    '28007'|       0| 35.72|    0|                0.0|\n",
      "|   0|     623|  1|     0|   '28007'|       1|    '28007'|       0| 25.81|    0|                0.0|\n",
      "|   0|     586|  4|     0|   '28007'|       1|    '28007'|       0|   9.1|    0|                0.0|\n",
      "|   0|     987|  2|     0|   '28007'|       1|    '28007'|       0| 21.17|    0|                0.0|\n",
      "|   0|    3407|  1|     1|   '28007'|       1|    '28007'|       0|  32.4|    0|                0.0|\n",
      "|   0|    2765|  3|     0|   '28007'|       1|    '28007'|       0|  35.4|    0|                0.0|\n",
      "|   0|    2660|  2|     0|   '28007'|       1|    '28007'|       0| 14.95|    0|                0.0|\n",
      "|   0|    2202|  4|     1|   '28007'|       0|    '28007'|       0|  1.51|    0|                0.0|\n",
      "|   0|    3547|  1|     1|   '28007'|      19|    '28007'|       2| 68.79|    0|0.05021834061135371|\n",
      "|   0|    1593|  3|     1|   '28007'|       0|    '28007'|       0| 20.32|    0|                0.0|\n",
      "|   0|     864|  1|     1|   '28007'|       1|    '28007'|       0| 13.56|    0|                0.0|\n",
      "|   0|    2392|  1|     0|   '28007'|       1|    '28007'|       0| 30.19|    0|                0.0|\n",
      "|   0|    1678|  2|     1|   '28007'|       0|    '28007'|       0| 17.54|    0|                0.0|\n",
      "|   0|      59|  3|     0|   '28007'|       1|    '28007'|       0| 40.69|    0|                0.0|\n",
      "|   0|    1436|  0|     1|   '28007'|       1|    '28007'|       0| 21.21|    0|                0.0|\n",
      "|   0|    3698|  0|     0|   '28007'|       1|    '28007'|       0| 10.09|    0|                0.0|\n",
      "+----+--------+---+------+----------+--------+-----------+--------+------+-----+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputCols = [\n",
    " 'customer',\n",
    " 'age',\n",
    " 'gender',\n",
    " 'merchant',\n",
    " 'category',\n",
    " 'amount',\n",
    "#  'merchanttProbablity'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=inputCols, outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = assembler.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+---+------+----------+--------+-----------+--------+------+-----+-------------------+--------------------+\n",
      "|step|customer|age|gender|zipcodeOri|merchant|zipMerchant|category|amount|fraud|merchanttProbablity|            features|\n",
      "+----+--------+---+------+----------+--------+-----------+--------+------+-----+-------------------+--------------------+\n",
      "|   0|    1795|  2|     1|   '28007'|       1|    '28007'|       0|  4.55|    0|                0.0|[1795.0,2.0,1.0,1...|\n",
      "|   0|    1620|  0|     1|   '28007'|       1|    '28007'|       0| 39.68|    0|                0.0|[1620.0,0.0,1.0,1...|\n",
      "|   0|    3796|  2|     0|   '28007'|       0|    '28007'|       0| 26.89|    0|                0.0|[3796.0,2.0,0.0,0...|\n",
      "|   0|    1273|  1|     1|   '28007'|       1|    '28007'|       0| 17.25|    0|                0.0|[1273.0,1.0,1.0,1...|\n",
      "|   0|    2814|  3|     1|   '28007'|       1|    '28007'|       0| 35.72|    0|                0.0|[2814.0,3.0,1.0,1...|\n",
      "|   0|     623|  1|     0|   '28007'|       1|    '28007'|       0| 25.81|    0|                0.0|[623.0,1.0,0.0,1....|\n",
      "|   0|     586|  4|     0|   '28007'|       1|    '28007'|       0|   9.1|    0|                0.0|[586.0,4.0,0.0,1....|\n",
      "|   0|     987|  2|     0|   '28007'|       1|    '28007'|       0| 21.17|    0|                0.0|[987.0,2.0,0.0,1....|\n",
      "|   0|    3407|  1|     1|   '28007'|       1|    '28007'|       0|  32.4|    0|                0.0|[3407.0,1.0,1.0,1...|\n",
      "|   0|    2765|  3|     0|   '28007'|       1|    '28007'|       0|  35.4|    0|                0.0|[2765.0,3.0,0.0,1...|\n",
      "|   0|    2660|  2|     0|   '28007'|       1|    '28007'|       0| 14.95|    0|                0.0|[2660.0,2.0,0.0,1...|\n",
      "|   0|    2202|  4|     1|   '28007'|       0|    '28007'|       0|  1.51|    0|                0.0|[2202.0,4.0,1.0,0...|\n",
      "|   0|    3547|  1|     1|   '28007'|      19|    '28007'|       2| 68.79|    0|0.05021834061135371|[3547.0,1.0,1.0,1...|\n",
      "|   0|    1593|  3|     1|   '28007'|       0|    '28007'|       0| 20.32|    0|                0.0|[1593.0,3.0,1.0,0...|\n",
      "|   0|     864|  1|     1|   '28007'|       1|    '28007'|       0| 13.56|    0|                0.0|[864.0,1.0,1.0,1....|\n",
      "|   0|    2392|  1|     0|   '28007'|       1|    '28007'|       0| 30.19|    0|                0.0|[2392.0,1.0,0.0,1...|\n",
      "|   0|    1678|  2|     1|   '28007'|       0|    '28007'|       0| 17.54|    0|                0.0|[1678.0,2.0,1.0,0...|\n",
      "|   0|      59|  3|     0|   '28007'|       1|    '28007'|       0| 40.69|    0|                0.0|[59.0,3.0,0.0,1.0...|\n",
      "|   0|    1436|  0|     1|   '28007'|       1|    '28007'|       0| 21.21|    0|                0.0|[1436.0,0.0,1.0,1...|\n",
      "|   0|    3698|  0|     0|   '28007'|       1|    '28007'|       0| 10.09|    0|                0.0|[3698.0,0.0,0.0,1...|\n",
      "+----+--------+---+------+----------+--------+-----------+--------+------+-----+-------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validation, test = df.randomSplit([0.7, 0.1, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+--------------------+\n",
      "|prediction|fraud|            features|\n",
      "+----------+-----+--------------------+\n",
      "|       1.0|    1|[1.0,3.0,0.0,9.0,...|\n",
      "|       0.0|    0|[4.0,4.0,0.0,1.0,...|\n",
      "|       0.0|    0|[5.0,0.0,0.0,1.0,...|\n",
      "|       0.0|    0|[10.0,5.0,1.0,17....|\n",
      "|       0.0|    0|[24.0,1.0,1.0,1.0...|\n",
      "+----------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "ROC: 0.7182501879635009\n",
      "accuracy: 0.9921012658227848\n",
      "Elapsed time is: 18.287577867507935\n"
     ]
    }
   ],
   "source": [
    "# With 1 Worker\n",
    "\n",
    "start = time()\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "rf = RandomForestClassifier(labelCol=\"fraud\", featuresCol=\"features\", numTrees=10)\n",
    "pipeline = Pipeline(stages=[rf])\n",
    "\n",
    "# Train model.  This also runs the indexers.\n",
    "model = pipeline.fit(train)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(test)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions = predictions.withColumn(\"fraud\", predictions[\"fraud\"].cast(DoubleType()))\n",
    "\n",
    "roc_evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"prediction\", labelCol=\"fraud\", metricName=\"areaUnderROC\")\n",
    "print('ROC: {}'.format(roc_evaluator.evaluate(predictions)))\n",
    "\n",
    "accuracy_evaluator = MulticlassClassificationEvaluator(labelCol=\"fraud\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "print('accuracy: {}'.format(accuracy_evaluator.evaluate(predictions)))\n",
    "print('Elapsed time is: {}'.format(time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
